{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEKSxmCS5CIZ"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'FedGAN (Python 3.7.4)' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'conda install -n FedGAN ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Do this if using Colab....\n",
        "!pip install matplotlib==3.5.2\n",
        "!pip install numpy==1.22.0 --no-dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqVmtaVcZNSi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "import copy\n",
        "# import tensorflow.keras.backend as K\n",
        "import random\n",
        "\n",
        "from IPython import display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noctzt18ZR8g"
      },
      "outputs": [],
      "source": [
        "\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "# Defined by the number of parameters\n",
        "THRESHOLD = [1664,204928,823553]\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE * 10).batch(BATCH_SIZE * 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_dataset_noniid(train_dataset, num_discriminators):\n",
        "  micro_batch = []\n",
        "  discriminator_dataset = []\n",
        "  sample = random.sample(range(100), num_discriminators)\n",
        "  sample_sum = sum(sample)\n",
        "  sample = [s/sample_sum for s in sample]\n",
        "  current = 0 \n",
        "  for k in range (num_discriminators):\n",
        "    sample_size = int(sample[k] * 2560)\n",
        "    batch = train_dataset[current:current+sample_size,:,:,:]\n",
        "    discriminator_dataset.append(batch)\n",
        "    current = current+ sample_size\n",
        "  return discriminator_dataset\n",
        "\n",
        "\n",
        "def split_dataset_iid(train_dataset, num_discriminators):\n",
        "  discriminator_dataset = []\n",
        "  current = 0\n",
        "  for i in range (num_discriminators):\n",
        "    sample_size = int(2560/num_discriminators)\n",
        "    batch = train_dataset[current:current+sample_size,:,:,:]\n",
        "    discriminator_dataset.append(batch)\n",
        "    current = current+ sample_size\n",
        "  return discriminator_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzrP6dcpZTxH"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model()\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "  \n",
        "# Num_of_params = 1664\n",
        "def make_discriminator_part_A():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  return model\n",
        "\n",
        "# Num_of_params = 204,928\n",
        "def make_discriminator_part_B():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "\n",
        "  \n",
        "  return model\n",
        "# Num_of_params = 823,553\n",
        "def make_discriminator_part_C():\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
        "  model.add(layers.LeakyReLU())\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1))   \n",
        "  return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErWwaQiQZWCp"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq-gUWGxZYhk"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def aggregation(model_list):\n",
        "    base = model_list[0]\n",
        "    base_models = []\n",
        "    for client in base:\n",
        "      for client_part in client:\n",
        "        base_models.append(copy.deepcopy(client_part.get_weights()))\n",
        "    base_A = [base_models[0]]\n",
        "    base_B = [base_models[1]]\n",
        "    base_C = [base_models[2]]\n",
        "    current_pointer = 1\n",
        "    for model in model_list[1:]:\n",
        "        for client in model:\n",
        "          for client_part in client:\n",
        "            if current_pointer == 1:\n",
        "              base_A.append(copy.deepcopy(client_part.get_weights()))\n",
        "              current_pointer += 1\n",
        "            elif current_pointer == 2:\n",
        "              base_B.append(copy.deepcopy(client_part.get_weights()))\n",
        "              current_pointer += 1\n",
        "            elif current_pointer == 3:\n",
        "              base_C.append(copy.deepcopy(client_part.get_weights()))\n",
        "              current_pointer = 1\n",
        "    \n",
        "    # FedAVG\n",
        "    averaged_A = np.mean(base_A, axis = 0)\n",
        "    averaged_B = np.mean(base_B, axis = 0)\n",
        "    averaged_C = np.mean(base_C, axis = 0)\n",
        "    current_pointer = 1\n",
        "    for model in model_list:\n",
        "      for client in model:\n",
        "        for client_part in client:\n",
        "          if current_pointer == 1:\n",
        "            client_part.set_weights(averaged_A)\n",
        "            current_pointer += 1\n",
        "          elif current_pointer == 2:\n",
        "            client_part.set_weights(averaged_B)\n",
        "            current_pointer += 1\n",
        "          elif current_pointer == 3:\n",
        "            client_part.set_weights(averaged_C)\n",
        "            current_pointer = 1\n",
        "\n",
        "    return model_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D62UkM9TxA6G"
      },
      "outputs": [],
      "source": [
        "\n",
        "def split_method_preprocessing_time(client_capacities, client_time_factor):\n",
        "    clients = zip(client_time_factor, client_capacities)\n",
        "    clients = list(clients)\n",
        "\n",
        "    # Implement the selection algorithm here\n",
        "    # Default example: Sort by client time factor: i.e. faster is better\n",
        "    clients.sort()\n",
        "    sorted_capacities = []\n",
        "    sorted_time_factor = []\n",
        "    for client_sorted in clients:\n",
        "        sorted_time_factor.append(client_sorted[0])\n",
        "        sorted_capacities.append(client_sorted[1])\n",
        "        \n",
        "    return sorted_capacities[:3], sorted_time_factor[:3]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sqbK8fPmYFS"
      },
      "outputs": [],
      "source": [
        "def randomly_select_clients_preprocess(client_capacities, client_time_factor):\n",
        "    clients = zip(client_time_factor, client_capacities)\n",
        "    clients = list(clients)\n",
        "    random.shuffle(clients)\n",
        "    sorted_capacities = []\n",
        "    sorted_time_factor = []\n",
        "    for client_sorted in clients:\n",
        "        sorted_time_factor.append(client_sorted[0])\n",
        "        sorted_capacities.append(client_sorted[1])\n",
        "    \n",
        "    return sorted_capacities[:3], sorted_time_factor[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFXiL2HzrNMi"
      },
      "outputs": [],
      "source": [
        "def split_method_preprocessing_capacity(client_capacities, client_time_factor):\n",
        "    clients = zip(client_capacities, client_time_factor)\n",
        "    clients = list(clients)\n",
        "\n",
        "    # Implement the selection algorithm here\n",
        "    # Default example: Sort by client time factor: i.e. faster is better\n",
        "    clients.sort()\n",
        "    sorted_capacities = []\n",
        "    sorted_time_factor = []\n",
        "    for client_sorted in clients:\n",
        "        sorted_time_factor.append(client_sorted[1])\n",
        "        sorted_capacities.append(client_sorted[0])\n",
        "        \n",
        "    return sorted_capacities[:3], sorted_time_factor[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE7TfCASZhdX"
      },
      "outputs": [],
      "source": [
        "def split_method_for_D_by_capacity(device_capacities):\n",
        "    discriminators = []\n",
        "    discriminator = []\n",
        "    discriminator_optimizer = []\n",
        "    discriminators_optimizer = []\n",
        "    current_pointer = 0\n",
        "    for device in device_capacities:\n",
        "        part = []\n",
        "        part_optimizer = []\n",
        "        capacity = device\n",
        "        while capacity >= THRESHOLD[current_pointer]:\n",
        "            if orders[current_pointer] == \"A\":\n",
        "                # Do something\n",
        "                discri_part = make_discriminator_part_A()\n",
        "                part.append(discri_part)\n",
        "                optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
        "                part_optimizer.append(optimizer_part)\n",
        "                current_pointer += 1\n",
        "            elif orders[current_pointer] == \"B\":\n",
        "                discri_part = make_discriminator_part_B()\n",
        "                part.append(discri_part)\n",
        "                optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
        "                # Do something\n",
        "                part_optimizer.append(optimizer_part)\n",
        "                current_pointer += 1\n",
        "            elif orders[current_pointer] == \"C\":\n",
        "                discri_part = make_discriminator_part_C()\n",
        "                part.append(discri_part)\n",
        "                current_pointer = 0\n",
        "                discriminator.append(part)\n",
        "                discriminators.append(discriminator)\n",
        "                optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
        "                part_optimizer.append(optimizer_part)\n",
        "                discriminator_optimizer.append(part_optimizer)\n",
        "                discriminators_optimizer.append(discriminator_optimizer)\n",
        "                part = []\n",
        "                discriminator = []\n",
        "                part_optimizer = []\n",
        "                discriminator_optimizer = []\n",
        "                return discriminators, discriminators_optimizer\n",
        "            capacity -= THRESHOLD[current_pointer]\n",
        "        if len(part) != 0:\n",
        "            discriminator.append(part)\n",
        "            discriminator_optimizer.append(part_optimizer)\n",
        "        else:\n",
        "            continue\n",
        "    # Only reached when NO device has enough capacity\n",
        "    return discriminators, discriminators_optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0BWTnzXWlbt"
      },
      "outputs": [],
      "source": [
        "def split_method_for_D_by_capacity_baseline(client_capacities):\n",
        "    discriminators = []\n",
        "    discriminator = []\n",
        "    discriminator_optimizer = []\n",
        "    discriminators_optimizer = []\n",
        "    current_pointer = 0\n",
        "\n",
        "    while client_capacities != []:\n",
        "      for client in client_capacities:\n",
        "          part = []\n",
        "          part_optimizer = []\n",
        "          capacity = client\n",
        "          if capacity >= THRESHOLD[current_pointer]:\n",
        "              if orders[current_pointer] == \"A\":\n",
        "                  # Do something\n",
        "                  discri_part = make_discriminator_part_A()\n",
        "                  part.append(discri_part)\n",
        "                  optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
        "                  part_optimizer.append(optimizer_part)\n",
        "                  discriminator.append(part)\n",
        "                  discriminator_optimizer.append(part_optimizer)\n",
        "                  current_pointer += 1\n",
        "              elif orders[current_pointer] == \"B\":\n",
        "                  discri_part = make_discriminator_part_B()\n",
        "                  part.append(discri_part)\n",
        "                  optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
        "                  # Do something\n",
        "                  part_optimizer.append(optimizer_part)\n",
        "                  discriminator.append(part)\n",
        "                  discriminator_optimizer.append(part_optimizer)\n",
        "                  current_pointer += 1\n",
        "              elif orders[current_pointer] == \"C\":\n",
        "                  discri_part = make_discriminator_part_C()\n",
        "                  part.append(discri_part)\n",
        "                  discriminator.append(part)\n",
        "                  optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
        "                  part_optimizer.append(optimizer_part)\n",
        "                  discriminator_optimizer.append(part_optimizer)\n",
        "\n",
        "                  discriminators.append(discriminator)\n",
        "                  discriminators_optimizer.append(discriminator_optimizer)\n",
        "                  current_pointer = 0\n",
        "                  discriminator = []\n",
        "                  discriminator_optimizer = []\n",
        "                  return discriminators, discriminators_optimizer\n",
        "          else:\n",
        "              client_capacities.remove(capacity)\n",
        "\n",
        "            \n",
        "            \n",
        "    return discriminators, discriminators_optimizer    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahx3lGKLZg8s"
      },
      "outputs": [],
      "source": [
        "global CLIENT_CAPACITIES\n",
        "global CLIENT_TIME_FACTOR\n",
        "global discriminator_list\n",
        "global discriminator_optimizer_list\n",
        "global devices_time_sorted\n",
        "\n",
        "discriminator_list = []\n",
        "discriminator_optimizer_list = []\n",
        "# CLIENT_CAPACITIES = [1000000, 80000000, 90000000, 10000000, 5000000, 100000, 3000, 967000, 900000, 6000000, 13500000, 4000000, 60000]\n",
        "# CLIENT_TIME_FACTOR = [1, 1.5, 2, 0.747, 1, 1.458, 7, 1.343, 4, 2.136, 2.747, 1.343, 3]\n",
        "\n",
        "# SELECTION_METHOD = \"RANDOM/TIME\"\n",
        "SELECTION_METHOD = \"RANDOM\"\n",
        "\n",
        "# List of clients, each client contains the information of their devices\n",
        "# NB: One discriminator refers to ONE client\n",
        "CLIENTS_CAPACITIES = [ [100000, 20000000, 30000000, 90000000] , [100000, 20000000, 30000000, 90000000] , [600000, 10000000, 30000000, 90000000], [700000, 20000000, 30000000, 90000000], [900000, 20000000, 30000000, 90000000], [10, 10, 10, 10] ]\n",
        "CLIENT_TIME_FACTOR = [ [3, 2, 2.5, 4], [7, 4, 3.5, 2.3] , [1.7, 1.5, 6, 0.7], [4, 1.5, 2.34, 1], [1.67, 2, 2.5, 4], [999,999,999,999]]\n",
        "# CLIENT_CAPACITIES_ORI = [60000, 1000000, 5000000,7000000 , 90000000, 100000000, 9000000000]\n",
        "# CLIENT_TIME_FACTOR_ORI = [1, 1, 3,  1, 1.5 , 1, 1]\n",
        "\n",
        "\n",
        "# For model evaluation\n",
        "NUM_OF_CLIENTS = 5\n",
        "CLIENTS_CAPACITIES = [[823553, 823553, 823553] for i in range(NUM_OF_CLIENTS)]\n",
        "CLIENT_TIME_FACTOR = [[1, 1, 1] for i in range(NUM_OF_CLIENTS)]\n",
        "\n",
        "\n",
        "orders = [\"A\", \"B\", \"C\"]\n",
        "\n",
        "false_clients = 0\n",
        "devices_time_sorted = []\n",
        "for client_index in range(len(CLIENTS_CAPACITIES)):\n",
        "  client_capacity = CLIENTS_CAPACITIES[client_index]\n",
        "  client_time = CLIENT_TIME_FACTOR[client_index]\n",
        "  if SELECTION_METHOD == \"RANDOM\":\n",
        "    client_cap_sorted, client_time_sorted = randomly_select_clients_preprocess(client_capacity, client_time)\n",
        "  else:\n",
        "    client_cap_sorted, client_time_sorted = split_method_preprocessing_time(client_capacity, client_time)\n",
        "  client_discrimiantor, client_optimizer = split_method_for_D_by_capacity(client_cap_sorted)\n",
        "  # client_discrimiantor, client_optimizer = split_method_for_D_by_capacity_baseline(client_cap_sorted)\n",
        "\n",
        "  if len(client_discrimiantor) != 0:\n",
        "    devices_time_sorted += client_time_sorted\n",
        "    discriminator_list += client_discrimiantor\n",
        "    discriminator_optimizer_list += client_optimizer\n",
        "  else:\n",
        "    false_clients += 1\n",
        "\n",
        "print(\"Number of false clients: \" + str(false_clients))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DkJGeqbZpTl"
      },
      "outputs": [],
      "source": [
        "# Some naming is confusing here, need to be reformed\n",
        "def train_step_clients(discriminator_list, discriminator_optimizer_list, images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    # noise = tf.random.normal([25, noise_dim])\n",
        "    gen_loss = None\n",
        "\n",
        "    client_times = []\n",
        "    # 50 ms for each round of LAN communication\n",
        "    LAN_communication_time = 0.05\n",
        "\n",
        "    # For iid setting\n",
        "    discriminator_dataset = split_dataset_iid(images, len(discriminator_list))\n",
        "\n",
        "    # For non iid setting\n",
        "    discriminator_dataset = split_dataset_noniid(images, len(discriminator_list))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        for index in range (len(discriminator_list)):\n",
        "            discriminator = discriminator_list[index]\n",
        "            gradients = []\n",
        "            current_d_time = []\n",
        "\n",
        "            with tf.GradientTape(persistent=True) as disc_tape:\n",
        "                # current_real_input = random.choice(micro_batch)\n",
        "                current_real_input = discriminator_dataset[index]\n",
        "                # current_real_input = images\n",
        "                current_fake_input = generated_images\n",
        "                for device_index in range(len(discriminator)):\n",
        "                    current_client_time_start = time.time()\n",
        "                    current_device = discriminator[device_index]\n",
        "                    for device_part in current_device:\n",
        "                        current_real_input = device_part(current_real_input, training=True)\n",
        "                        current_fake_input = device_part(current_fake_input, training=True)\n",
        "\n",
        "                    current_client_time_end = time.time()\n",
        "                    current_client_time_gap = current_client_time_end - current_client_time_start\n",
        "                    current_d_time.append(current_client_time_gap)\n",
        "\n",
        "\n",
        "                if gen_loss == None:\n",
        "                    gen_loss = generator_loss(current_fake_input)\n",
        "                else:\n",
        "                    gen_loss += generator_loss(current_fake_input)\n",
        "                disc_loss = discriminator_loss(current_real_input, current_fake_input)\n",
        "\n",
        "\n",
        "            client_time_index = 1\n",
        "            for device_index_r in range(len(discriminator)-1, -1, -1):\n",
        "                client_parts = discriminator[device_index_r]\n",
        "                client_gradients = []\n",
        "                current_client_time_start = time.time()\n",
        "                for device_part_index_r in range(len(client_parts)-1, -1, -1):\n",
        "                    device_part = client_parts[device_part_index_r]\n",
        "                    gradient_part = disc_tape.gradient(disc_loss, device_part.trainable_variables)\n",
        "                    client_gradients.append(gradient_part)\n",
        "                current_client_time_end = time.time()\n",
        "                current_client_time_gap = current_client_time_end - current_client_time_start\n",
        "                current_d_time[-client_time_index] += current_client_time_gap\n",
        "                client_time_index += 1\n",
        "                gradients.append(client_gradients)\n",
        "\n",
        "\n",
        "            client_time_index = 1\n",
        "            for client_index_r in range(len(discriminator)-1, -1, -1):\n",
        "                client_parts = discriminator[client_index_r]\n",
        "                current_client_time_start = time.time()\n",
        "                for client_part_index_r in range(len(client_parts)-1, -1, -1):\n",
        "                    client_part = client_parts[client_part_index_r]\n",
        "                    part_optimizer = discriminator_optimizer_list[index][client_index_r][client_part_index_r]\n",
        "                    gradient = gradients[-client_index_r-1][-client_part_index_r-1]\n",
        "                    part_optimizer.apply_gradients(zip(gradient, client_part.trainable_variables))\n",
        "                current_client_time_end = time.time()\n",
        "                current_client_time_gap = current_client_time_end - current_client_time_start\n",
        "                current_d_time[-client_time_index] += current_client_time_gap\n",
        "                client_time_index += 1\n",
        "\n",
        "\n",
        "\n",
        "            # concatenate the time cost of different clients\n",
        "            client_times += current_d_time\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "    # Final processing on client times\n",
        "    for time_index in range(len(client_times)):\n",
        "        client_times[time_index] *= devices_time_sorted[time_index]\n",
        "    client_time_index = 0\n",
        "    discrimiantor_time_costs = [0 for i in range (len(discriminator_list))]\n",
        "\n",
        "\n",
        "    for discriminator_clients_index in range(len(discriminator_list)):\n",
        "        client_numbers_in_single_D = len(discriminator_list[discriminator_clients_index])\n",
        "        for client_id in range(client_numbers_in_single_D):\n",
        "            client_time = client_times[client_time_index]\n",
        "            client_time_index += 1\n",
        "            discrimiantor_time_costs[discriminator_clients_index] += client_time + LAN_communication_time\n",
        "\n",
        "\n",
        "    return client_times, discrimiantor_time_costs, gen_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-xKal3NZrfQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "\n",
        "EPOCHS = 500\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNEMm09AZtcO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(dataset, epochs):\n",
        "  \n",
        "\n",
        "  # CLIENT_CAPACITIES, CLIENT_TIME_FACTOR = split_method_preprocessing_time(CLIENT_CAPACITIES_ORI, CLIENT_TIME_FACTOR_ORI)\n",
        "\n",
        "  # CLIENT_CAPACITIES, CLIENT_TIME_FACTOR = randomly_select_clients_preprocess(CLIENT_CAPACITIES_ORI, CLIENT_TIME_FACTOR_ORI)\n",
        "  # discriminator_list,discriminator_optimizer_list = split_method_for_D_by_capacity(CLIENT_CAPACITIES)\n",
        "  \n",
        "  # discriminator_list,discriminator_optimizer_list = split_method_for_D_by_capacity_baseline(CLIENT_CAPACITIES)\n",
        "  global discriminator_list\n",
        "  global discriminator_optimizer_list\n",
        "  print(len(discriminator_list))\n",
        "  gloss_list= []\n",
        "  time_list = []\n",
        "  \n",
        "  for epoch in range(epochs):\n",
        "    gloss = []\n",
        "    client_time_list = None\n",
        "    d_time_list = None\n",
        "    # print(epoch)\n",
        "    start = time.time()\n",
        "    for image_batch in dataset:\n",
        "      \n",
        "      # gloss_val = train_step(image_batch)\n",
        "      client_times, d_times, gen_loss = train_step_clients(discriminator_list, discriminator_optimizer_list, image_batch)\n",
        "      if client_time_list == None:\n",
        "        client_time_list = client_times\n",
        "        d_time_list = d_times\n",
        "      else:\n",
        "        client_time_list = [sum(x) for x in zip(client_time_list, client_times)]\n",
        "        d_time_list = [sum(x) for x in zip(d_time_list, d_times)]\n",
        "      gloss.append(gen_loss)\n",
        "    gloss_val = sum(gloss)/ len(gloss)\n",
        "    # If yo want to print the g_loss\n",
        "    # print(gloss_val.numpy())\n",
        "    gloss_list.append(gloss_val)\n",
        "    discriminator_list = aggregation(discriminator_list)\n",
        "\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "      generate_and_save_images(generator,\n",
        "                           epoch,\n",
        "                           seed)\n",
        "      \n",
        "    \n",
        "\n",
        "\n",
        "    # Time for each clients in this EPOCH    \n",
        "    # print(client_time_list)\n",
        "    # print(d_time_list)\n",
        "    # print('-' * 30)\n",
        "    limit = max(d_time_list)\n",
        "    print('The slowest discrminator takes {} sec to finish the current epoch'.format(limit))\n",
        "    print(\"-\" * 50)\n",
        "    time_list.append(limit)\n",
        "\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    # display.clear_output(wait=True)\n",
        "    # generate_and_save_images(generator,\n",
        "    #                          epoch + 1,\n",
        "    #                          seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    # if (epoch + 1) % 15 == 0:\n",
        "    #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    # print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  # display.clear_output(wait=True)\n",
        "  \n",
        "\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)\n",
        "  return client_time_list,time_list, gloss_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymJBZMuDdd1d"
      },
      "outputs": [],
      "source": [
        "client_time_list, limit_time_list, gloss_list = train(train_dataset, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyoMc2C4GyQs"
      },
      "outputs": [],
      "source": [
        "averaged_time = sum(limit_time_list)/len(limit_time_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxcbNBy1G_-o"
      },
      "outputs": [],
      "source": [
        "print(averaged_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqvHY-lRLQH9"
      },
      "outputs": [],
      "source": [
        "print(len(gloss_list))\n",
        "for loss in gloss_list:\n",
        "  print(loss.numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dcsfgan_3parts.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "FedGAN",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
