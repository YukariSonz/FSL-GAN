{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEKSxmCS5CIZ"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'FedGAN (Python 3.7.4)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n FedGAN ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do this if using Colab....\n",
    "!pip install matplotlib==3.5.2\n",
    "!pip install numpy==1.22.0 --no-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "VqVmtaVcZNSi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import copy\n",
    "# import tensorflow.keras.backend as K\n",
    "import random\n",
    "\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "noctzt18ZR8g"
   },
   "outputs": [],
   "source": [
    "\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Defined by the number of parameters\n",
    "THRESHOLD = [1664,204928,823553]\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).batch(BATCH_SIZE * 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_noniid(train_dataset, distribution, num_discriminators):\n",
    "  micro_batch = []\n",
    "  discriminator_dataset = []\n",
    "  current = 0 \n",
    "  for k in range (num_discriminators):\n",
    "    sample_size = int(distribution[k] * 2560)\n",
    "    print(sample_size)\n",
    "    batch = train_dataset[current:current+sample_size,:,:,:]\n",
    "    discriminator_dataset.append(batch)\n",
    "    current = current+ sample_size\n",
    "  return discriminator_dataset\n",
    "\n",
    "\n",
    "def split_dataset_iid(train_dataset, num_discriminators):\n",
    "  discriminator_dataset = []\n",
    "  current = 0\n",
    "  for i in range (num_discriminators):\n",
    "    sample_size = int(2560/num_discriminators)\n",
    "    batch = train_dataset[current:current+sample_size,:,:,:]\n",
    "    discriminator_dataset.append(batch)\n",
    "    current = current+ sample_size\n",
    "  return discriminator_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "RzrP6dcpZTxH"
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "  \n",
    "# Num_of_params = 1664\n",
    "def make_discriminator_part_A():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  return model\n",
    "\n",
    "# Num_of_params = 204,928\n",
    "def make_discriminator_part_B():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "\n",
    "  \n",
    "  return model\n",
    "# Num_of_params = 823,553\n",
    "def make_discriminator_part_C():\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "  model.add(layers.LeakyReLU())\n",
    "  model.add(layers.Dropout(0.3))\n",
    "  model.add(layers.Flatten())\n",
    "  model.add(layers.Dense(1))   \n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ErWwaQiQZWCp"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Eq-gUWGxZYhk"
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def aggregation(model_list):\n",
    "    base = model_list[0]\n",
    "    base_models = []\n",
    "    for client in base:\n",
    "      for client_part in client:\n",
    "        base_models.append(copy.deepcopy(client_part.get_weights()))\n",
    "    base_A = [base_models[0]]\n",
    "    base_B = [base_models[1]]\n",
    "    base_C = [base_models[2]]\n",
    "    current_pointer = 1\n",
    "    for model in model_list[1:]:\n",
    "        for client in model:\n",
    "          for client_part in client:\n",
    "            if current_pointer == 1:\n",
    "              base_A.append(copy.deepcopy(client_part.get_weights()))\n",
    "              current_pointer += 1\n",
    "            elif current_pointer == 2:\n",
    "              base_B.append(copy.deepcopy(client_part.get_weights()))\n",
    "              current_pointer += 1\n",
    "            elif current_pointer == 3:\n",
    "              base_C.append(copy.deepcopy(client_part.get_weights()))\n",
    "              current_pointer = 1\n",
    "    \n",
    "    # FedAVG\n",
    "    averaged_A = np.mean(base_A, axis = 0)\n",
    "    averaged_B = np.mean(base_B, axis = 0)\n",
    "    averaged_C = np.mean(base_C, axis = 0)\n",
    "    current_pointer = 1\n",
    "    for model in model_list:\n",
    "      for client in model:\n",
    "        for client_part in client:\n",
    "          if current_pointer == 1:\n",
    "            client_part.set_weights(averaged_A)\n",
    "            current_pointer += 1\n",
    "          elif current_pointer == 2:\n",
    "            client_part.set_weights(averaged_B)\n",
    "            current_pointer += 1\n",
    "          elif current_pointer == 3:\n",
    "            client_part.set_weights(averaged_C)\n",
    "            current_pointer = 1\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "D62UkM9TxA6G"
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_method_preprocessing_time(client_capacities, client_time_factor):\n",
    "    clients = zip(client_time_factor, client_capacities)\n",
    "    clients = list(clients)\n",
    "\n",
    "    # Implement the selection algorithm here\n",
    "    # Default example: Sort by client time factor: i.e. faster is better\n",
    "    clients.sort()\n",
    "    sorted_capacities = []\n",
    "    sorted_time_factor = []\n",
    "    for client_sorted in clients:\n",
    "        sorted_time_factor.append(client_sorted[0])\n",
    "        sorted_capacities.append(client_sorted[1])\n",
    "        \n",
    "    return sorted_capacities[:3], sorted_time_factor[:3]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "_sqbK8fPmYFS"
   },
   "outputs": [],
   "source": [
    "def randomly_select_clients_preprocess(client_capacities, client_time_factor):\n",
    "    clients = zip(client_time_factor, client_capacities)\n",
    "    clients = list(clients)\n",
    "    random.shuffle(clients)\n",
    "    sorted_capacities = []\n",
    "    sorted_time_factor = []\n",
    "    for client_sorted in clients:\n",
    "        sorted_time_factor.append(client_sorted[0])\n",
    "        sorted_capacities.append(client_sorted[1])\n",
    "    \n",
    "    return sorted_capacities[:3], sorted_time_factor[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "xFXiL2HzrNMi"
   },
   "outputs": [],
   "source": [
    "def split_method_preprocessing_capacity(client_capacities, client_time_factor):\n",
    "    clients = zip(client_capacities, client_time_factor)\n",
    "    clients = list(clients)\n",
    "\n",
    "    # Implement the selection algorithm here\n",
    "    # Default example: Sort by client time factor: i.e. faster is better\n",
    "    clients.sort()\n",
    "    sorted_capacities = []\n",
    "    sorted_time_factor = []\n",
    "    for client_sorted in clients:\n",
    "        sorted_time_factor.append(client_sorted[1])\n",
    "        sorted_capacities.append(client_sorted[0])\n",
    "        \n",
    "    return sorted_capacities[:3], sorted_time_factor[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "gE7TfCASZhdX"
   },
   "outputs": [],
   "source": [
    "def split_method_for_D_by_capacity(device_capacities):\n",
    "    discriminators = []\n",
    "    discriminator = []\n",
    "    discriminator_optimizer = []\n",
    "    discriminators_optimizer = []\n",
    "    current_pointer = 0\n",
    "    for device in device_capacities:\n",
    "        part = []\n",
    "        part_optimizer = []\n",
    "        capacity = device\n",
    "        while capacity >= THRESHOLD[current_pointer]:\n",
    "            if orders[current_pointer] == \"A\":\n",
    "                # Do something\n",
    "                discri_part = make_discriminator_part_A()\n",
    "                part.append(discri_part)\n",
    "                optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
    "                part_optimizer.append(optimizer_part)\n",
    "                current_pointer += 1\n",
    "            elif orders[current_pointer] == \"B\":\n",
    "                discri_part = make_discriminator_part_B()\n",
    "                part.append(discri_part)\n",
    "                optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
    "                # Do something\n",
    "                part_optimizer.append(optimizer_part)\n",
    "                current_pointer += 1\n",
    "            elif orders[current_pointer] == \"C\":\n",
    "                discri_part = make_discriminator_part_C()\n",
    "                part.append(discri_part)\n",
    "                current_pointer = 0\n",
    "                discriminator.append(part)\n",
    "                discriminators.append(discriminator)\n",
    "                optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
    "                part_optimizer.append(optimizer_part)\n",
    "                discriminator_optimizer.append(part_optimizer)\n",
    "                discriminators_optimizer.append(discriminator_optimizer)\n",
    "                part = []\n",
    "                discriminator = []\n",
    "                part_optimizer = []\n",
    "                discriminator_optimizer = []\n",
    "                return discriminators, discriminators_optimizer\n",
    "            capacity -= THRESHOLD[current_pointer]\n",
    "        if len(part) != 0:\n",
    "            discriminator.append(part)\n",
    "            discriminator_optimizer.append(part_optimizer)\n",
    "        else:\n",
    "            continue\n",
    "    # Only reached when NO device has enough capacity\n",
    "    return discriminators, discriminators_optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "T0BWTnzXWlbt"
   },
   "outputs": [],
   "source": [
    "def split_method_for_D_by_capacity_baseline(client_capacities):\n",
    "    discriminators = []\n",
    "    discriminator = []\n",
    "    discriminator_optimizer = []\n",
    "    discriminators_optimizer = []\n",
    "    current_pointer = 0\n",
    "\n",
    "    while client_capacities != []:\n",
    "      for client in client_capacities:\n",
    "          part = []\n",
    "          part_optimizer = []\n",
    "          capacity = client\n",
    "          if capacity >= THRESHOLD[current_pointer]:\n",
    "              if orders[current_pointer] == \"A\":\n",
    "                  # Do something\n",
    "                  discri_part = make_discriminator_part_A()\n",
    "                  part.append(discri_part)\n",
    "                  optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
    "                  part_optimizer.append(optimizer_part)\n",
    "                  discriminator.append(part)\n",
    "                  discriminator_optimizer.append(part_optimizer)\n",
    "                  current_pointer += 1\n",
    "              elif orders[current_pointer] == \"B\":\n",
    "                  discri_part = make_discriminator_part_B()\n",
    "                  part.append(discri_part)\n",
    "                  optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
    "                  # Do something\n",
    "                  part_optimizer.append(optimizer_part)\n",
    "                  discriminator.append(part)\n",
    "                  discriminator_optimizer.append(part_optimizer)\n",
    "                  current_pointer += 1\n",
    "              elif orders[current_pointer] == \"C\":\n",
    "                  discri_part = make_discriminator_part_C()\n",
    "                  part.append(discri_part)\n",
    "                  discriminator.append(part)\n",
    "                  optimizer_part = tf.keras.optimizers.Adam(1e-4)\n",
    "                  part_optimizer.append(optimizer_part)\n",
    "                  discriminator_optimizer.append(part_optimizer)\n",
    "\n",
    "                  discriminators.append(discriminator)\n",
    "                  discriminators_optimizer.append(discriminator_optimizer)\n",
    "                  current_pointer = 0\n",
    "                  discriminator = []\n",
    "                  discriminator_optimizer = []\n",
    "                  return discriminators, discriminators_optimizer\n",
    "          else:\n",
    "              client_capacities.remove(capacity)\n",
    "\n",
    "            \n",
    "            \n",
    "    return discriminators, discriminators_optimizer    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ahx3lGKLZg8s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of false clients: 0\n"
     ]
    }
   ],
   "source": [
    "global CLIENT_CAPACITIES\n",
    "global CLIENT_TIME_FACTOR\n",
    "global discriminator_list\n",
    "global discriminator_optimizer_list\n",
    "global devices_time_sorted\n",
    "\n",
    "discriminator_list = []\n",
    "discriminator_optimizer_list = []\n",
    "# CLIENT_CAPACITIES = [1000000, 80000000, 90000000, 10000000, 5000000, 100000, 3000, 967000, 900000, 6000000, 13500000, 4000000, 60000]\n",
    "# CLIENT_TIME_FACTOR = [1, 1.5, 2, 0.747, 1, 1.458, 7, 1.343, 4, 2.136, 2.747, 1.343, 3]\n",
    "\n",
    "# SELECTION_METHOD = \"RANDOM/TIME\"\n",
    "SELECTION_METHOD = \"RANDOM\"\n",
    "\n",
    "# List of clients, each client contains the information of their devices\n",
    "# NB: One discriminator refers to ONE client\n",
    "CLIENTS_CAPACITIES = [ [100000, 20000000, 30000000, 90000000] , [100000, 20000000, 30000000, 90000000] , [600000, 10000000, 30000000, 90000000], [700000, 20000000, 30000000, 90000000], [900000, 20000000, 30000000, 90000000], [10, 10, 10, 10] ]\n",
    "CLIENT_TIME_FACTOR = [ [3, 2, 2.5, 4], [7, 4, 3.5, 2.3] , [1.7, 1.5, 6, 0.7], [4, 1.5, 2.34, 1], [1.67, 2, 2.5, 4], [999,999,999,999]]\n",
    "# CLIENT_CAPACITIES_ORI = [60000, 1000000, 5000000,7000000 , 90000000, 100000000, 9000000000]\n",
    "# CLIENT_TIME_FACTOR_ORI = [1, 1, 3,  1, 1.5 , 1, 1]\n",
    "\n",
    "\n",
    "# For model evaluation\n",
    "NUM_OF_CLIENTS = 5\n",
    "CLIENTS_CAPACITIES = [[823553, 823553, 823553] for i in range(NUM_OF_CLIENTS)]\n",
    "CLIENT_TIME_FACTOR = [[1, 1, 1] for i in range(NUM_OF_CLIENTS)]\n",
    "\n",
    "\n",
    "orders = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "false_clients = 0\n",
    "devices_time_sorted = []\n",
    "for client_index in range(len(CLIENTS_CAPACITIES)):\n",
    "  client_capacity = CLIENTS_CAPACITIES[client_index]\n",
    "  client_time = CLIENT_TIME_FACTOR[client_index]\n",
    "  if SELECTION_METHOD == \"RANDOM\":\n",
    "    client_cap_sorted, client_time_sorted = randomly_select_clients_preprocess(client_capacity, client_time)\n",
    "  else:\n",
    "    client_cap_sorted, client_time_sorted = split_method_preprocessing_time(client_capacity, client_time)\n",
    "  client_discrimiantor, client_optimizer = split_method_for_D_by_capacity(client_cap_sorted)\n",
    "  # client_discrimiantor, client_optimizer = split_method_for_D_by_capacity_baseline(client_cap_sorted)\n",
    "\n",
    "  if len(client_discrimiantor) != 0:\n",
    "    devices_time_sorted += client_time_sorted\n",
    "    discriminator_list += client_discrimiantor\n",
    "    discriminator_optimizer_list += client_optimizer\n",
    "  else:\n",
    "    false_clients += 1\n",
    "\n",
    "print(\"Number of false clients: \" + str(false_clients))\n",
    "\n",
    "\n",
    "sample = random.sample(range(100), len(discriminator_list))\n",
    "sample_sum = sum(sample)\n",
    "sample_distribution = [s/sample_sum for s in sample]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "2DkJGeqbZpTl"
   },
   "outputs": [],
   "source": [
    "# Some naming is confusing here, need to be reformed\n",
    "def train_step_clients(discriminator_list, discriminator_optimizer_list, images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    # noise = tf.random.normal([25, noise_dim])\n",
    "    gen_loss = None\n",
    "\n",
    "    client_times = []\n",
    "    # 50 ms for each round of LAN communication\n",
    "    LAN_communication_time = 0.05\n",
    "\n",
    "    # For iid setting\n",
    "    discriminator_dataset = split_dataset_iid(images, len(discriminator_list))\n",
    "\n",
    "    # For non iid setting\n",
    "    discriminator_dataset = split_dataset_noniid(images, sample_distribution, len(discriminator_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        for index in range (len(discriminator_list)):\n",
    "            discriminator = discriminator_list[index]\n",
    "            gradients = []\n",
    "            current_d_time = []\n",
    "\n",
    "            with tf.GradientTape(persistent=True) as disc_tape:\n",
    "                # current_real_input = random.choice(micro_batch)\n",
    "                current_real_input = discriminator_dataset[index]\n",
    "                # current_real_input = images\n",
    "                current_fake_input = generated_images\n",
    "                for device_index in range(len(discriminator)):\n",
    "                    current_client_time_start = time.time()\n",
    "                    current_device = discriminator[device_index]\n",
    "                    for device_part in current_device:\n",
    "                        current_real_input = device_part(current_real_input, training=True)\n",
    "                        current_fake_input = device_part(current_fake_input, training=True)\n",
    "\n",
    "                    current_client_time_end = time.time()\n",
    "                    current_client_time_gap = current_client_time_end - current_client_time_start\n",
    "                    current_d_time.append(current_client_time_gap)\n",
    "\n",
    "\n",
    "                if gen_loss == None:\n",
    "                    gen_loss = generator_loss(current_fake_input)\n",
    "                else:\n",
    "                    gen_loss += generator_loss(current_fake_input)\n",
    "                disc_loss = discriminator_loss(current_real_input, current_fake_input)\n",
    "\n",
    "\n",
    "            client_time_index = 1\n",
    "            for device_index_r in range(len(discriminator)-1, -1, -1):\n",
    "                client_parts = discriminator[device_index_r]\n",
    "                client_gradients = []\n",
    "                current_client_time_start = time.time()\n",
    "                for device_part_index_r in range(len(client_parts)-1, -1, -1):\n",
    "                    device_part = client_parts[device_part_index_r]\n",
    "                    gradient_part = disc_tape.gradient(disc_loss, device_part.trainable_variables)\n",
    "                    client_gradients.append(gradient_part)\n",
    "                current_client_time_end = time.time()\n",
    "                current_client_time_gap = current_client_time_end - current_client_time_start\n",
    "                current_d_time[-client_time_index] += current_client_time_gap\n",
    "                client_time_index += 1\n",
    "                gradients.append(client_gradients)\n",
    "\n",
    "\n",
    "            client_time_index = 1\n",
    "            for client_index_r in range(len(discriminator)-1, -1, -1):\n",
    "                client_parts = discriminator[client_index_r]\n",
    "                current_client_time_start = time.time()\n",
    "                for client_part_index_r in range(len(client_parts)-1, -1, -1):\n",
    "                    client_part = client_parts[client_part_index_r]\n",
    "                    part_optimizer = discriminator_optimizer_list[index][client_index_r][client_part_index_r]\n",
    "                    gradient = gradients[-client_index_r-1][-client_part_index_r-1]\n",
    "                    part_optimizer.apply_gradients(zip(gradient, client_part.trainable_variables))\n",
    "                current_client_time_end = time.time()\n",
    "                current_client_time_gap = current_client_time_end - current_client_time_start\n",
    "                current_d_time[-client_time_index] += current_client_time_gap\n",
    "                client_time_index += 1\n",
    "\n",
    "\n",
    "\n",
    "            # concatenate the time cost of different clients\n",
    "            client_times += current_d_time\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "    # Final processing on client times\n",
    "    for time_index in range(len(client_times)):\n",
    "        client_times[time_index] *= devices_time_sorted[time_index]\n",
    "    client_time_index = 0\n",
    "    discrimiantor_time_costs = [0 for i in range (len(discriminator_list))]\n",
    "\n",
    "\n",
    "    for discriminator_clients_index in range(len(discriminator_list)):\n",
    "        client_numbers_in_single_D = len(discriminator_list[discriminator_clients_index])\n",
    "        for client_id in range(client_numbers_in_single_D):\n",
    "            client_time = client_times[client_time_index]\n",
    "            client_time_index += 1\n",
    "            discrimiantor_time_costs[discriminator_clients_index] += client_time + LAN_communication_time\n",
    "\n",
    "\n",
    "    return client_times, discrimiantor_time_costs, gen_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "e-xKal3NZrfQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "\n",
    "EPOCHS = 500\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "vNEMm09AZtcO"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(dataset, epochs):\n",
    "  \n",
    "\n",
    "  # CLIENT_CAPACITIES, CLIENT_TIME_FACTOR = split_method_preprocessing_time(CLIENT_CAPACITIES_ORI, CLIENT_TIME_FACTOR_ORI)\n",
    "\n",
    "  # CLIENT_CAPACITIES, CLIENT_TIME_FACTOR = randomly_select_clients_preprocess(CLIENT_CAPACITIES_ORI, CLIENT_TIME_FACTOR_ORI)\n",
    "  # discriminator_list,discriminator_optimizer_list = split_method_for_D_by_capacity(CLIENT_CAPACITIES)\n",
    "  \n",
    "  # discriminator_list,discriminator_optimizer_list = split_method_for_D_by_capacity_baseline(CLIENT_CAPACITIES)\n",
    "  global discriminator_list\n",
    "  global discriminator_optimizer_list\n",
    "  print(len(discriminator_list))\n",
    "  gloss_list= []\n",
    "  time_list = []\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "    gloss = []\n",
    "    client_time_list = None\n",
    "    d_time_list = None\n",
    "    # print(epoch)\n",
    "    start = time.time()\n",
    "    for image_batch in dataset:\n",
    "      \n",
    "      # gloss_val = train_step(image_batch)\n",
    "      client_times, d_times, gen_loss = train_step_clients(discriminator_list, discriminator_optimizer_list, image_batch)\n",
    "      if client_time_list == None:\n",
    "        client_time_list = client_times\n",
    "        d_time_list = d_times\n",
    "      else:\n",
    "        client_time_list = [sum(x) for x in zip(client_time_list, client_times)]\n",
    "        d_time_list = [sum(x) for x in zip(d_time_list, d_times)]\n",
    "      gloss.append(gen_loss)\n",
    "    gloss_val = sum(gloss)/ len(gloss)\n",
    "    # If yo want to print the g_loss\n",
    "    # print(gloss_val.numpy())\n",
    "    gloss_list.append(gloss_val)\n",
    "    discriminator_list = aggregation(discriminator_list)\n",
    "\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "      generate_and_save_images(generator,\n",
    "                           epoch,\n",
    "                           seed)\n",
    "      \n",
    "    \n",
    "\n",
    "\n",
    "    # Time for each clients in this EPOCH    \n",
    "    # print(client_time_list)\n",
    "    # print(d_time_list)\n",
    "    # print('-' * 30)\n",
    "    limit = max(d_time_list)\n",
    "    # print('The slowest discrminator takes {} sec to finish the current epoch'.format(limit))\n",
    "    # print(\"-\" * 50)\n",
    "    time_list.append(limit)\n",
    "\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    # display.clear_output(wait=True)\n",
    "    # generate_and_save_images(generator,\n",
    "    #                          epoch + 1,\n",
    "    #                          seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    # if (epoch + 1) % 15 == 0:\n",
    "    #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    # print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  # display.clear_output(wait=True)\n",
    "  \n",
    "\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)\n",
    "  return client_time_list,time_list, gloss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "ymJBZMuDdd1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "620\n",
      "475\n",
      "329\n",
      "174\n",
      "960\n",
      "620\n",
      "475\n",
      "329\n",
      "174\n",
      "960\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13028\\2918915523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclient_time_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit_time_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgloss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13028\\1554564986.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m       \u001b[1;31m# gloss_val = train_step(image_batch)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m       \u001b[0mclient_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step_clients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator_optimizer_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mclient_time_list\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mclient_time_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient_times\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13028\\2274360064.py\u001b[0m in \u001b[0;36mtrain_step_clients\u001b[1;34m(discriminator_list, discriminator_optimizer_list, images)\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mdevice_part_index_r\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient_parts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0mdevice_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient_parts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdevice_part_index_r\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                     \u001b[0mgradient_part\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisc_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                     \u001b[0mclient_gradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_part\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mcurrent_client_time_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\fedGAN\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\fedGAN\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda\\envs\\fedGAN\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\fedGAN\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    590\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m           data_format=data_format),\n\u001b[0m\u001b[0;32m    593\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0;32m    594\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\fedGAN\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[1;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[1;34m\"explicit_paddings\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data_format\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m         \"dilations\", dilations)\n\u001b[0m\u001b[0;32m   1242\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client_time_list, limit_time_list, gloss_list = train(train_dataset, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyoMc2C4GyQs"
   },
   "outputs": [],
   "source": [
    "averaged_time = sum(limit_time_list)/len(limit_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxcbNBy1G_-o"
   },
   "outputs": [],
   "source": [
    "print(averaged_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqvHY-lRLQH9"
   },
   "outputs": [],
   "source": [
    "print(len(gloss_list))\n",
    "for loss in gloss_list:\n",
    "  print(loss.numpy())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcsfgan_3parts.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
